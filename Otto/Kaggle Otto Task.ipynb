{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This document is about the Kaggle challenge [Otto Group Product Classification Challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First some general statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains 61878 entries and the final competition test contains 144368 entries.\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.csv\") as f:\n",
    "    lines = f.readlines()\n",
    "with open(\"test.csv\") as f:\n",
    "    lines_competition_test = f.readlines()\n",
    "print(\"The training set contains %i entries and the final competition test contains %i entries.\" %\n",
    "      (len(lines)-1, len(lines_competition_test)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,feat_1,feat_2,feat_3,feat_4,feat_5,feat_6,feat_7,feat_8,feat_9,feat_10,feat_11,feat_12,feat_13,feat_14,feat_15,feat_16,feat_17,feat_18,feat_19,feat_20,feat_21,feat_22,feat_23,feat_24,feat_25,feat_26,feat_27,feat_28,feat_29,feat_30,feat_31,feat_32,feat_33,feat_34,feat_35,feat_36,feat_37,feat_38,feat_39,feat_40,feat_41,feat_42,feat_43,feat_44,feat_45,feat_46,feat_47,feat_48,feat_49,feat_50,feat_51,feat_52,feat_53,feat_54,feat_55,feat_56,feat_57,feat_58,feat_59,feat_60,feat_61,feat_62,feat_63,feat_64,feat_65,feat_66,feat_67,feat_68,feat_69,feat_70,feat_71,feat_72,feat_73,feat_74,feat_75,feat_76,feat_77,feat_78,feat_79,feat_80,feat_81,feat_82,feat_83,feat_84,feat_85,feat_86,feat_87,feat_88,feat_89,feat_90,feat_91,feat_92,feat_93,target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,feat_1,feat_2,feat_3,feat_4,feat_5,feat_6,feat_7,feat_8,feat_9,feat_10,feat_11,feat_12,feat_13,feat_14,feat_15,feat_16,feat_17,feat_18,feat_19,feat_20,feat_21,feat_22,feat_23,feat_24,feat_25,feat_26,feat_27,feat_28,feat_29,feat_30,feat_31,feat_32,feat_33,feat_34,feat_35,feat_36,feat_37,feat_38,feat_39,feat_40,feat_41,feat_42,feat_43,feat_44,feat_45,feat_46,feat_47,feat_48,feat_49,feat_50,feat_51,feat_52,feat_53,feat_54,feat_55,feat_56,feat_57,feat_58,feat_59,feat_60,feat_61,feat_62,feat_63,feat_64,feat_65,feat_66,feat_67,feat_68,feat_69,feat_70,feat_71,feat_72,feat_73,feat_74,feat_75,feat_76,feat_77,feat_78,feat_79,feat_80,feat_81,feat_82,feat_83,feat_84,feat_85,feat_86,feat_87,feat_88,feat_89,feat_90,feat_91,feat_92,feat_93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines_competition_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0, 'id': 1, 'features': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 4, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 11, 0, 1, 1, 0, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "144368\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for line in lines[1:]:  # Skip header\n",
    "    line = line.strip().split(\",\")\n",
    "    dataset.append({'id': int(line[0]),\n",
    "                    'features': [int(feature) for feature in line[1:-1]],\n",
    "                    'target': int(line[-1][-1])-1}) # target is Class_i, where i is 1,...,9\n",
    "print(dataset[0])\n",
    "\n",
    "dataset_competition_test = []\n",
    "for line in lines_competition_test[1:]:  # Skip header\n",
    "    line = line.strip().split(\",\")\n",
    "    dataset_competition_test.append({'id': int(line[0]),\n",
    "                                     'features': [int(feature) for feature in line[1:]]})\n",
    "print(len(dataset_competition_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has  1929 training examples.\n",
      "Class 1 has 16122 training examples.\n",
      "Class 2 has  8004 training examples.\n",
      "Class 3 has  2691 training examples.\n",
      "Class 4 has  2739 training examples.\n",
      "Class 5 has 14135 training examples.\n",
      "Class 6 has  2839 training examples.\n",
      "Class 7 has  8464 training examples.\n",
      "Class 8 has  4955 training examples.\n"
     ]
    }
   ],
   "source": [
    "class_data = {}\n",
    "for data in dataset:\n",
    "    if data['target'] not in class_data:\n",
    "        class_data[data['target']] = 1\n",
    "    else:\n",
    "        class_data[data['target']] += 1\n",
    "\n",
    "for class_name, counter in sorted(class_data.items()):\n",
    "    print(\"Class {0} has {1:>5} training examples.\".format(class_name, counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[61, 51, 64, 70, 19, 10, 38, 76, 43, 30, 38, 30, 72, 33, 46, 37, 43, 32, 121, 27, 14, 22, 64, 263, 30, 33, 123, 22, 69, 87, 59, 149, 24, 84, 105, 84, 22, 39, 78, 41, 36, 41, 42, 34, 80, 41, 47, 49, 81, 73, 44, 48, 53, 63, 27, 62, 30, 117, 97, 40, 38, 56, 51, 73, 38, 36, 104, 109, 76, 46, 31, 30, 352, 231, 80, 102, 29, 80, 25, 54, 26, 24, 79, 76, 55, 65, 67, 30, 61, 130, 52, 19, 87]\n",
      "Competition set\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[64, 45, 84, 82, 14, 11, 44, 100, 47, 59, 37, 30, 75, 34, 39, 46, 49, 30, 128, 31, 28, 28, 76, 213, 30, 62, 71, 24, 69, 122, 64, 141, 32, 86, 104, 86, 25, 42, 85, 43, 48, 43, 32, 35, 76, 54, 45, 70, 79, 73, 49, 79, 64, 86, 31, 58, 38, 202, 84, 39, 37, 56, 55, 62, 64, 36, 112, 173, 80, 43, 65, 35, 352, 398, 87, 102, 28, 100, 32, 60, 33, 28, 91, 132, 56, 73, 54, 37, 62, 119, 74, 22, 91]\n",
      "Max max: 398\n"
     ]
    }
   ],
   "source": [
    "mins = [dataset[0]['features'][i] for i in range(93)]\n",
    "maxs = [dataset[0]['features'][i] for i in range(93)]\n",
    "for data in dataset:\n",
    "    for i in range(93):\n",
    "        mins[i] = min(mins[i], data['features'][i])\n",
    "        maxs[i] = max(maxs[i], data['features'][i])\n",
    "print(mins)\n",
    "print(maxs)\n",
    "\n",
    "print(\"Competition set\")\n",
    "mins = [dataset_competition_test[0]['features'][i] for i in range(93)]\n",
    "maxs = [dataset_competition_test[0]['features'][i] for i in range(93)]\n",
    "for data in dataset_competition_test:\n",
    "    for i in range(93):\n",
    "        mins[i] = min(mins[i], data['features'][i])\n",
    "        maxs[i] = max(maxs[i], data['features'][i])\n",
    "print(mins)\n",
    "print(maxs)\n",
    "print(\"Max max: %i\" % max(maxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of maxima by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. for class 0: [25, 10, 7, 5, 19, 5, 19, 56, 7, 26]\n",
      "Max. for class 1: [22, 5, 6, 7, 13, 3, 9, 14, 41, 24]\n",
      "Max. for class 2: [22, 7, 5, 5, 4, 3, 7, 13, 43, 22]\n",
      "Max. for class 3: [30, 2, 5, 9, 5, 2, 2, 6, 20, 30]\n",
      "Max. for class 4: [3, 2, 4, 5, 2, 1, 1, 6, 15, 4]\n",
      "Max. for class 5: [11, 26, 64, 67, 12, 10, 9, 21, 18, 12]\n",
      "Max. for class 6: [13, 39, 10, 10, 5, 3, 15, 22, 17, 30]\n",
      "Max. for class 7: [61, 51, 44, 70, 11, 8, 38, 23, 29, 22]\n",
      "Max. for class 8: [13, 5, 6, 11, 6, 3, 8, 76, 15, 22]\n"
     ]
    }
   ],
   "source": [
    "for class_i in range(9):\n",
    "    maxs = [0 for i in range(93)]\n",
    "    for data in dataset:\n",
    "        if data['target'] != class_i:\n",
    "            continue\n",
    "        for i in range(93):\n",
    "            maxs[i] = max(maxs[i], data['features'][i])\n",
    "    print(\"Max. for class %i: %s\" % (class_i, str(maxs[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAfQAAABUCAYAAAB0vcXQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAADF9JREFUeJzt3XuMXGUdxvHvAgq0YC2kpRYF7w9glAQoWKptadAit0ZB\n",
       "QAiVUrRGUNCgQWOgWA2JiFqJeKulyCUB0hhBRGuhpCgglyjFqD/RYtpQoGCk3ZbQy3b9433XjmO7\n",
       "M7Pd3Tmd9/kkm5w5czI5T2c6vznnvL/zdvX29mJmZma7tz3avQNmZma261zQzczMOoALupmZWQdw\n",
       "QTczM+sALuhmZmYdwAXdzMysA+zV35OSLgTOr1l1DHA4cAvpx8BzwPkRsVnSecClwDbgRxGxUNJr\n",
       "gEXAIUAPMCsinpF0JHAD0AusiIhPD24sMzOzsnQ124cuaTJwFjACuCciFkv6OrAauBl4ApgAbAEe\n",
       "AyYDpwPHRMRnJH0AmB0R50haBlweEU9IuhW4OSJ+NdjhzMzMStHKKfcrgXnAVOCuvO5u4ETgWOCx\n",
       "iOiOiFeB3wGTgGnAz/K29wGT8lH7myPiibrXMDMzswFqqqBLmgCsiogXgJERsSU/9SLwBmBcXu6z\n",
       "tmb9SwARsY10in0c8O8dbGtmZmYD1O819BoXka6F1+vayfatrG/qR0Vvb29vV9fOXtbMzKzjtFT0\n",
       "mi3oU4CL8/IGSXtHxCbgYGBN/htXs/3BwCM161fkU+1dpIF0B9Ztu6bRDnR1dfHii91N7m5nGTNm\n",
       "/2Kzg/M7f7n5S84Ozj9mzP4tbd/w6FjSeGBDRGzNq5YCZ+blM4B7gd8DEySNkrQf6fr5cmAJ8NG8\n",
       "7WnA/fl1/ippUl7/4fwaZmZmNkDNnO6eBbxD0uOSTgZ+CFwv6WXSKPbb8kC4e4BnSUfgyyKiG1gM\n",
       "TJO0DlhAalUD+D7wy7z+0Ii4f1BTmZmZFabfgi7pQGAmMB44FZgBXAJ8IiJeD9wKXCBpJHASaXDb\n",
       "GNJo9tHAx4BfRsQo4GzgsvzSlwLT8vo/Szpp0JOZmZkVpNE19BOBpRGxEdgIzJG0EpiTn78buBwI\n",
       "ctsagKTatrWb8rb3AQv7aVvrtw998uTJbNnS00q2YXPmmWczc+asdu+GmZkVrFFBPxQYIennwGjg\n",
       "anahbU3SgNvWHnzwwYZh2uW44ya2exfMzKxwjQr6HsABpIFrbwYeqHt+2NrW0hn9LzW36bC5GVjA\n",
       "iBGvbXk0YquG+vWrzvmdv1QlZwfnb0Wjgv488HC+KcxKSd3AZkn75IFww9a2ll5mchORhtNvAXjl\n",
       "lc1D2lrh1g3nd/4y85ecHZx/sNvWlpBGqXflAXIjSW1rZ+Tn3bZmZmZWAY0K+juBicA64BngSdy2\n",
       "ZmZmVjnNXL++NyJel/9mAJ/FbWtmZmaV0kxBrx/INgXPtmZmZlYpjQbF9QJH5La1A4Cv0qa2NTMz\n",
       "M9u5RgX9aWBuRNwp6a2ktrU9a54fxra16nLb2tBzfucvVcnZwflb0W9Bj4g1wJ15eaWk54Gj2zHb\n",
       "WpW5bW1oOb/zl5q/5Ozg/IPatibpXElX5eWxpAFvN+LZ1szMzCql0enuu0hH5A8Bq0htaDfgtjUz\n",
       "M7NK6begR8SGiDgdWEbqQX8K+AxuWzMzM6uUhgPSJB0GHEY6Age3rZmZmVVOMyPMrwU+x/YR6gNu\n",
       "WyO1wbltzczMbJD1O8pd0kxgeUSskgT/33bmtjXctjYcnN/5S1VydnD+VjTqQz8ZeKukjwBvBDYB\n",
       "3e2Zba263LY2tJzf+UvNX3J2cP5BbVuLiHMi4tiImEgapT6PdC3cs62ZmZlVSKNT7iOARcBY4G3A\n",
       "HaTZ1pZK+h7wMvDFiHhVUl/bWi9wa0R0S1oMfC23p/WQjvhhe9sawEq3rZmZme2aRtevTwUejYip\n",
       "pKPu04BLcNuamZlZpTS69esdNQ8PAVYDU4E5ed3dwOVAkNvWACTVtq3dlLe9D1jYT9var3Y1jJmZ\n",
       "WamaGmGe7xR3C+kI221rZmZmFdNolDsAEXG8pCNJp9hruW0Nt60NB+d3/lKVnB2cvxWNBsUdDayN\n",
       "iNUR8aSkvXDb2v9x29rQcn7nLzV/ydnB+Qe1bQ14P/B5AEkHASOBpbhtzczMrFIaFfQfAGMlrQb+\n",
       "DrxKKt6fzLOtnU0a3b4NuAJ4nHQEvgepkN8O7CVpLfAT4O2S3kK6Fv9dSeuBY9g+HauZmZkNQKMb\n",
       "y7xKuqHMiojYH5gIXA38A5gdEQcBTwMXkkap9wDjgXeT7v8+CngAuD0iRgNXAddExF+A9cAJEfFG\n",
       "YJRb18zMzAaumQFpy4Gz8vI60ml3z7hmZmZWIQ0LekT0RMTG/HA2aRrV/dy6ZmZmVh1Nta0BSJoB\n",
       "zAKmk06z9ym+dc1ta0PP+Z2/VCVnB+dvRVMFXdJ04MvA9IhYL2mDpL0jYhNuXXPb2hBzfucvNX/J\n",
       "2cH5B7ttDUmjgGuBUyLi5bx6KdtHprt1zczMrM2aOdV9NnAQsFrS3yTdDywErs+ta6cDt+WBcH0z\n",
       "rj0HLMv3dl8MTMszri0Absiv2zfj2jrgUM+4ZmZmNnDNFPRbgBXAjcB3ImIa8Ck845qZmVllNFPQ\n",
       "N5GmUX2hZp3b1szMzCqk2ba1TXWrPeOamZlZhTTdttYPt625bW3IOb/zl6rk7OD8rRhoQXfbWg23\n",
       "rQ0t53f+UvOXnB2cf9Db1mp0sf3o2m1rZmZmFdLwCF3Se4EfA2OBrZLmkEazL8rL/wRuiogeSVcA\n",
       "vyZdJ58bEd2Sbgc+IOlB0mxtF+SXvgz4jaTXAd2kyVrMzMxsABoW9Ih4hDR7Wr0P7mDbxaS+89p1\n",
       "20izsdUbC/whIk6TdBipt/34ZnbazMzM/tdgDIobqP+2s0XEXyWNlrRfRGzY8eYvAU/s+Km2ebbd\n",
       "O2BmZga0t6CP438rdF/729M73vwX+a965s+/jvnzr2v3bpiZFWPtWl+lrdfOgl6vi3TtfYd6e3t3\n",
       "1gZnZmZWvHb2f9e3uY0ntbOZmZlZi9pZ0JeQW98kHQU8GxEb27g/ZmZmu62u3t6dnuUecpKuASYD\n",
       "PcDFEfFU23bGzMxsN9bWgm5mZmaDY7e+h7qZmZklLuhmZmYdwAXdzMysA1SpD32HJH0bOI7Uo35p\n",
       "RDze5l0acpLeQ7qL3rci4nuS3gTcTPoB9hxwfkRsbuc+DiVJ3wDeR/p8XgM8TiH5JY0AFpFujbwP\n",
       "MA9YQSH5ASTtC/wJ+CpwP4VklzQVuJOUHdL7fi1wCwXkB5B0HvAFYCtwJfAU5bz/FwLn16w6Bjic\n",
       "Ft7/Sh+hS5oCvD0ijgdmA99t8y4NufyFfh3bJ7mB9MV2fURMBv7Oju+N3xEknQC8K7/nJwHzgasp\n",
       "JD9wKvBoREwFzgK+TVn5Ab5CutczFPTZz5ZFxAn571LSD7oi8ks6kFTEJ5H+H8ygoM9+RCzse++B\n",
       "q4CbaPHzX+mCTt393oHReWrWTraJ9GF+oWbdFOCuvHw3cOJw79QwWk4qZADrgJEUlD8i7oiIb+aH\n",
       "hwCrgakUkj9P1HQYcE9eVcx7n9XfEbOk/CcCSyNiY0Q8HxFzKOizX+dK0o+5qbSQv+qn3Fu83/vu\n",
       "LyJ6gB5JtatHRsSWvNz3b9CRcv6+GwzNJn2xTy8lfx9JD5Hunnga6UuulPzXAhcDs/LjYj77pDNy\n",
       "R0j6OXAA6eispPyHAiNy/tGko/OS8gMgaQKwKiJekNRS/qofodfr937vhSjinvaSZpC+1C+pe6qI\n",
       "/PmSwwzg1rqnOja/pJnA8ohYlVfVZ+3Y7NnTwNyImAF8HPgJsGfN852efw/SD5kPAxcAN9Y93+n5\n",
       "+1xEGkdTr2H+qhd03+892SBp77x8MOnfpWNJmg58GfhQRKynoPySjs6DIImIJ0ln0bol7ZM36eT8\n",
       "JwMflfQw6UvtK5STnYhYExF35uWVwPOky4xFfPZJeR+OiG05fzcFvf81pgAP5eWWvvuqXtBLvt97\n",
       "F9t/kS0l/zsAZwD3tmWPhoGkUaTTrqdExMt5dTH5gfcDnweQdBBpDMFSUm7o4PwRcU5EHBsRE4EF\n",
       "pGuI91FAdgBJ50q6Ki+PBcaQjlJL+ewvAaZJ6soD5Ir57PeRNB7YEBFb86qWvvsqf+vX0u73Lum9\n",
       "wI9JbUtbgX+RRnsvIrUx/ROYla81dxxJnySN8PxbXtVLOv22gDLy70M61fomYF9gLmkcyU8pIH+f\n",
       "XNieIX3JF5E9D/i9jXTaeU/SNeQ/Ukh++O///9n54TxSy2pJ+Y8C5kXEKfnxOFrIX/mCbmZmZo1V\n",
       "/ZS7mZmZNcEF3czMrAO4oJuZmXUAF3QzM7MO4IJuZmbWAVzQzczMOoALupmZWQf4DzE0KfToUmaM\n",
       "AAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3486f10d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAfQAAABUCAYAAAB0vcXQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAADCFJREFUeJzt3XuMXGUdxvHvAgq0QC2k5X4R0adilEQuchEoTaHIrUHK\n",
       "RQhIKVIjIEjQEGK4akhERSEgWi5FLgmQxgAWEAslNQJyiVKM8gMshAYoBSNl20Ch7fjH+5adzk53\n",
       "3l2Gztnd55M0OXvmZHLm6cz85pzz/s7bVavVMDMzs8FtvU7vgJmZmX18LuhmZmZDgAu6mZnZEOCC\n",
       "bmZmNgS4oJuZmQ0BLuhmZmZDwAZ9PSjpNODkulV7AF8EbiP9GHgDODkiPpB0EnAOsAr4XUTcJOlT\n",
       "wExgB2AlMDUiXpa0G3AdUAPmR8T32vuyzMzMhpeu0j50SQcAxwEjgNkRMUvST4GFwK3AM8CewIfA\n",
       "U8ABwFHAHhFxtqSDgWkRcYKkucD5EfGMpNuBWyPiwXa/ODMzs+GiP6fcLwIuB8YD9+Z19wETgb2A\n",
       "pyKiOyLeB/4K7AdMAP6Qt30Y2C8fte8UEc80PIeZmZkNUFFBl7Qn8GpEvAmMjIgP80NvAVsDW+Xl\n",
       "1RbXrX8bICJWkU6xbwX8r8m2ZmZmNkB9XkOvczrpWnijrrVs35/1RT8qarVaratrbU9rZmY25PSr\n",
       "6JUW9AOBM/PyUkkbRsRyYFvg9fxvq7rttwWeqFs/P59q7yINpNuiYdvXW+1AV1cXb73VXbi7w9eY\n",
       "MZs6pwLOqZyzKuOcyjmrMmPGbNqv7VseHUvaBlgaESvyqjnAlLx8DPAA8DdgT0mjJG1Cun4+D3gI\n",
       "ODZveyTwSH6e5yXtl9cfnZ/DzMzMBqjkdPdU4POSnpZ0GPBb4BpJ75BGsd+RB8LNBl4jHYHPjYhu\n",
       "YBYwQdIS4AZSqxrAb4D78/odI+KRtr4qMzOzYabPgi5pC+AUYBvgCGAycBbwnYj4DHA7cKqkkcCh\n",
       "pMFtY0ij2UcD3wLuj4hRwPHAufmpzwEm5PX/knRo21+ZmZnZMNLqGvpEYE5ELAOWAdMlLQCm58fv\n",
       "A84Hgty2BiCpvm3tlrztw8BNfbSt9dmHPmXKFJYvX9HXJh0xceIhnHjiya03NDMz+wS1Kug7AiMk\n",
       "3QOMBi7lY7StSRpw29qsWbNavphO2Hprd9yZmVnntSro6wGbkwau7QQ82vD4OmtbS/ezObPVRuvQ\n",
       "bGAmG2/86X6PRPykVW1/qso5lXNWZZxTOWfVfq0K+iLg8XxTmAWSuoEPJG2UB8Kts7a19HtiSquN\n",
       "1qHXAHjvvQ8q1X7hdpAyzqmcsyrjnMo5qzLtblt7iDRKvSsPkBtJals7Jj/utjUzM7MKaFXQvwDs\n",
       "AywBXgaexW1rZmZmlVNy/fqBiNgs/5sMfB+3rZmZmVVKSUFvHMh2IJ5tzczMrFJaDYqrAbvmtrXN\n",
       "gcvoUNuamZmZrV2rgv4icElE3C1pZ1Lb2vp1j6/DtrVqctva4OWcyjmrMs6pnLNqvz4LekS8Dtyd\n",
       "lxdIWgTs3onZ1qrKbWuDk3Mq56zKOKdyzqpMW9vWJJ0o6eK8PJY04O1mPNuamZlZpbQ63X0v6Yj8\n",
       "MeBVUhvadbhtzczMrFL6LOgRsTQijgLmknrQnwPOxm1rZmZmldJyQJqkccA40hE4uG3NzMysckpG\n",
       "mF8J/ICeEeoDblsjtcG5bc3MzKzN+hzlLukUYF5EvCoJereduW3NbWuDlnMq56zKOKdyzqr9WvWh\n",
       "HwbsLOmbwHbAcqC7M7OtVZPb1gYn51TOWZVxTuWcVZm2tq1FxAkRsVdE7EMapX456Vq4Z1szMzOr\n",
       "kFan3EcAM4GxwOeAu0izrc2RdC3wDvCjiHhf0uq2tRpwe0R0S5oF/CS3p60kHfFDT9sawAK3rZmZ\n",
       "mX08ra5fHwE8GRHjSUfdRwJn4bY1MzOzSml169e76v7cAVgIjAem53X3AecDQW5bA5BU37Z2S972\n",
       "YeCmPtrWHvy4L8bMzGy4Khphnu8UdxvpCNtta2ZmZhXTapQ7ABGxr6TdSKfY67ltzW1rg5ZzKues\n",
       "yjincs6q/VoNitsdWBwRCyPiWUkb4La1NbhtbXByTuWcVRnnVM5ZlWlr2xqwP3AegKQtgZHAHNy2\n",
       "ZmZmVimtCvr1wFhJC4GXgPdJxfuMPNva8aTR7auAC4CnSUfg65EK+Z3ABpIWAzcCu0j6LOla/NWS\n",
       "3gX2oGc6VjMzMxuAVjeWeZ90Q5n5EbEpsA9wKfAfYFpEbAm8CJxGGqW+EtgG+DLp/u+jgEeBOyNi\n",
       "NHAxcEVE/Bt4FzgoIrYDRrl1zczMbOBKBqTNA47Ly0tIp90945qZmVmFtCzoEbEyIpblP6eRplHd\n",
       "xK1rZmZm1VHUtgYgaTIwFZhEOs2+2rBuXXPb2uDlnMo5qzLOqZyzar+igi5pEnAhMCki3pW0VNKG\n",
       "EbGcYd665ra1wck5lXNWZZxTOWdVpt1ta0gaBVwJHB4R7+TVc+gZme7WNTMzsw4rOdV9PLAlsFDS\n",
       "C5IeAW4Crsmta0cBd+SBcKtnXHsDmJvv7T4LmJBnXLsBuC4/7+oZ15YAO3rGNTMzs4ErKei3AfOB\n",
       "m4FfRcQE4Lt4xjUzM7PKKCnoy0nTqL5Zt85ta2ZmZhVS2ra2vGG1Z1wzMzOrkOK2tT64ba1i7RdV\n",
       "25+qck7lnFUZ51TOWbXfQAu629Yyt60NTs6pnLMq45zKOasybW9bq9NFz9G129bMzMwqpOURuqS9\n",
       "gRnAWGCFpOmk0ewz8/IrwC0RsVLSBcCfSNfJL4mIbkl3AgdL+gtptrZT81OfC/xZ0mZAN2myFjMz\n",
       "MxuAlgU9Ip4gzZ7W6JAm284i9Z3Xr1tFmo2t0Vjg7xFxpKRxpN72fUt22szMzNbUjkFxA/VRO1tE\n",
       "PC9ptKRNImJp883fBp5p/lBHLOz0DpiZmX2kkwV9K9as0Kvb315svvkf879qmTHjembMuL7Tu2Fm\n",
       "NiQsXuyrrwPVyYLeqIt07b2pWq22tjY4MzOzYa+T/d+NbW7bkNrZzMzMrJ86WdAfIre+Sfoq8FpE\n",
       "LOvg/piZmQ1aXbXaWs9yf+IkXQEcAKwEzoyI5zq2M2ZmZoNYRwu6mZmZtcegvYe6mZmZ9XBBNzMz\n",
       "GwJc0M3MzIaAKvWhNyXpKuBrpB71cyLi6Q7vUqVI+grpjnu/jIhrJW0P3Er6sfYGcHJEfNDJfawC\n",
       "ST8Dvk56z18BPI1z6kXSCGAm6dbMGwGXA/NxVk1J2hj4J3AZ8AjOaQ2SxgN3kzKC9F66ErgN59SL\n",
       "pJOAHwIrgIuA5+jHe6rSR+iSDgR2iYh9gWnA1R3epUrJX76/oGdCHEhfLNdExAHASzS/j/6wIukg\n",
       "4Ev5fXQo8GvgUpxTM0cAT0bEeOA44CqcVV9+TLovNfiztzZzI+Kg/O8c0o9E59RA0hakIr4f6XM4\n",
       "mX5+9ipd0Gm43zswOk/Nasly0n/8m3XrDgTuzcv3ARPX9U5V0DxScQJYAozEOTUVEXdFxM/znzuQ\n",
       "Ji0Yj7PqJU8qNQ6YnVf5PdVc410+nVNzE4E5EbEsIhZFxHT6+dmr+in3ft7vfXiJiJXASkn1q0dG\n",
       "xId5eXVew1rOafVNi6aRvoAnOae1k/QY6e6NR5K+ZJxVb1cCZwJT89/+7PVWA3aVdA+wOekshnNq\n",
       "bkdgRM5qNOnovF9ZVf0IvVGf93u3Xnz/+zqSJpO+fM9qeMg5NciXJyYDtzc85KwASacA8yLi1byq\n",
       "MRfnlLwIXBIRk4FvAzcC69c97px6rEf60XM0cCpwc8PjLbOqekH3/d77b6mkDfPytqQMhz1Jk4AL\n",
       "gW9ExLs4p6Yk7Z4HVhIRz5LO4nVL2ihv4qySw4BjJT0OnE66lu6cGkTE6xFxd15eACwiXTr1Z6+3\n",
       "RcDjEbEqZ9VNP99TVS/ovt97mS56fr3NIWcGHAM80JE9qhBJo0inRw+PiHfyaufU3P7AeQCStiSN\n",
       "N5hDygicFQARcUJE7BUR+wA3kAZ6PYxzWoOkEyVdnJfHAmNIR57+7PX2EDBBUlceINfvz17lb/3q\n",
       "+72vnaS9gRmkFqMVwH9Jo7hnklqOXgGm5mvIw5akM4CLgRfyqhrplNYNOKc15KOBG4HtgY2BS0jj\n",
       "WH6Ps2oqF6yXSV/IzqlOHsR8B+lU8vqk68L/wDk1lb+rpuU/Lye11xZnVfmCbmZmZq1V/ZS7mZmZ\n",
       "FXBBNzMzGwJc0M3MzIYAF3QzM7MhwAXdzMxsCHBBNzMzGwJc0M3MzIaA/wOSv9roTqFxTgAAAABJ\n",
       "RU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34869d7ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAfQAAABUCAYAAAB0vcXQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAADIlJREFUeJzt3XuMVOUdxvHvgspVKRrQar3ENHmspiXxVnVV0Kp4J9ZL\n",
       "jXe0KfGSok1JqhFvpCHVWqumpipVvCaKxniL1oI2tF5qNVE0kV81SrRVvLRVwQaUZfvH+66M48LM\n",
       "LLvM7LzPJ9lw9px3Ts6zM8w755z3905Hd3c3ZmZmNrgNafYBmJmZ2fpzh25mZtYG3KGbmZm1AXfo\n",
       "ZmZmbcAdupmZWRtwh25mZtYGNqrVQNLJwAxgFXAJ8ApwB+nDwHvAqRHxeW43HVgN3BQRt0jaGJgL\n",
       "bAd0AVMj4i1JE4AbgG5gUUSc0+/JzMzMCrLOM3RJW5A68U7gSGAKcDlwfUTsD7wBnClpFDAT+AEw\n",
       "CbhA0ljgJOA/EbEf8Etgdt71b4GfRsS+wBhJh/Z3MDMzs5LUuuR+EDA/Ij6LiKURMY3UYT+Utz+c\n",
       "2+wJ/D0ilkXECuBp0oeAA4EHctsFQGc+a98hIl6s2oeZmZn1Ua1L7tsDIyU9CIwlnZ2Piogv8vYP\n",
       "gW8CW+XlHh9UrP8IICJWS+rO6/7bS1szMzPro1od+hBgc+AYYAfgz1XbO9byuEbW1zUwb8KECS0/\n",
       "R+2MGTM45ZRTmn0YZmbWHtbWl/aqVoe+FHg2IlYDb0paBnwuaXi+tL4N8G7+2aricdsAz1WsX5Qv\n",
       "tXeQBtJtUdX23VoHumjRovoSNdGSJf/kww+X9ft+x43bdED2O1g4v/OXmr/k7OD848Zt2lD7Wh36\n",
       "E8BcSb8inamPAh4HjgXuyv8+BvwNmCNpDGk0eydpxPtmwPF5P0cBT0bEKkmLJXVGxNOks//rah/q\n",
       "0cAVDYXbcK4E7m72QZiZWcHW2aFHxLuS7iOdbQOcB7wA3C5pGrAEuC0iuiT9AvgjqRTtsohYJuke\n",
       "4GBJfwFWAGfk/ZwP3ChpCPBcRDxZ+1A3ByY0lm6DGdfsAzAzs8LVKlubRCo3+1/+OZj0IWCT3GQY\n",
       "MDQvD8/76wBG5HVDcxuAjSset0nF40auTwAzMzOrb0DaUxFxQP6ZDszCdehmZmYtpZ4OvXqU3URc\n",
       "h25mZtZSag2K6wZ2znXom5NGpbkO3czMrMXU6tBfJw1wmydpR1Id+tCK7RusDn0wGD16eMNlBvUa\n",
       "qP0OFs7v/KUqOTs4fyNqjnIH5uXlNyUtBXaTNCwiVrIB69AHg+XLV7gOfQA4v/OXmr/k7OD8jX6Y\n",
       "qTXK/SRJl+bl8aT6rFuB43KTyjr0PSSNkTSadP98Ian+/Pjc9ss6dGCxpM68/pi8DzMzM+ujWpfc\n",
       "HwLulvRX0qX2s4GXaEodupmZma1NrUvuy4GjJY0AXgW25Kv15D116F2sqUNfTf116N24Dt3MzGy9\n",
       "1Tsg7WLyaHXSSHfXoZuZmbWQmh26pJ2AnYBH8yrXoZuZmbWYes7QrwIuYE3JWZ/r0EmX2F2HbmZm\n",
       "1s/WeQ9d0mnAwoh4WxJ8vY7cdegVXIc+cJzf+UtVcnZw/kbUGuV+OLCjpB8C3wJWAsua8X3og4Hr\n",
       "0AeG8zt/qflLzg7O36916BFxYkTsGRF7A3NIX8yygFR/Dq5DNzMzawmNXu7uBi4FTpe0EPgGqQ59\n",
       "BdBTh/4nch06cA8wNNehnw1cmPdzPjA717e/4Tp0MzOz9VPrHvpIYC4wnlRnPgvXoZuZmbWcWmfo\n",
       "RwLPR8Qk4ATgGuByXIduZmbWUmrNFHdvxa/bAe+QOuxped3DwM+BINehA0iqrEO/LbddANyyjjr0\n",
       "x9c3jJmZWanquocu6RngTtK9b9ehm5mZtZi6OvSI2AeYAtxVtcl16GZmZi2g1qC43YAPIuKdiHhZ\n",
       "0ka4Dn2tPLHMwHF+5y9VydnB+RtRa2KZ/YDtSYPctgRGkWrGjyWdrVfWoc+RNIY04r0TmA5sRqpD\n",
       "f4KKOnRJiyV1RsTTpDr06/o9WRN4YpmB4fzOX2r+krOD8/frxDLA74Hxueb8EeAc4DJch25mZtZS\n",
       "ao1yXwGc3MumQ3ppez9wf9W61cCZvbR9Ddi/oSM1MzOztap1yR0ASVcC++b2s4EXgDtIZ/jvAadG\n",
       "xOeSTiZdal8N3BQRPWVqc0llb13A1Ih4S9IE4AbSyPdFEXFOvyYzMzMrSD3fh34AsEse6X4ocC2e\n",
       "XMbMzKyl1FMytpA0SxzAJ6SBcROBh/K6nolh9iRPLpMv1VdOLvNAbrsA6FzH5DJmZmbWBzU79Ijo\n",
       "iojP8q9nAY8Coz25jJmZWeuo6x46gKQpwFRgMvB6xSZPLpO5Dn3gOL/zl6rk7OD8jah3UNxk4CJg\n",
       "ckR8Kmm5pGERsRJPLvMl16EPDOd3/lLzl5wdnL+/69DJk8VcBRwRER/n1fOB4/Jy5eQye0gaI2k0\n",
       "6f75QtKkMsfntl9OLgMsltSZ1x+T92FmZmZ9UM8Z+o9IZ9PzJEG6B34GaWa4acAS0uQyXZJ6Jpfp\n",
       "Jk8uI+ke4OA8ucyK/FhIk8vcKGkI8JwnlzEzM+u7egbF3QQcRqojvy8iDiR12JvkJsOAoXl5eN5n\n",
       "BzAirxua2wBsXPG4TSoeN7LvEczMzKyeS+4jgatZc+YNcAWuQzczM2sZ9YwuXwkcCbxfsc516GZm\n",
       "Zi2k3jr0lVWrR7kO3czMrHXUXYe+Dq5Dz1yHPnCc3/lLVXJ2cP5G9LVDdx16L1yHPjCc3/lLzV9y\n",
       "dnD+fq9Dr9DBmrNr16GbmZm1kJpn6JL2Am4GxgOrcu35ocBc16GbmZm1hpodekQ8B3y3l02H9NL2\n",
       "fuD+qnWrgTN7afuapBeB7wN7S9o9Il6o98DNzMxsjf4YFNcnkiYC346IfSTtBNwC7NOs41k/1wIw\n",
       "c+aFzJx5YZOPZd0++ODTZh+CmZkNgKZ16FTUp0fEYkljJY2OiOW9N/8IeLH3TVa38eM3a/Yh1OQP\n",
       "HWZmjWtmh74VX+2he+rZX++9+SP5x9rdYPjQYWbto11OIprZoVfrYM3Usl/T3d29trp2MzOz4jVz\n",
       "QpfquvWtSfXpZmZm1qBmduhPkGvZJe0K/CsiPmvi8ZiZmQ1aHd3da73KPeAkzQb2B7qAcyPilaYd\n",
       "jJmZ2SDW1A7dzMzM+kdbfCmKmZlZ6dyhm5mZtQF36GZmZm2glerQeyXpGtJ8793A9BLme5f0PdIs\n",
       "er+JiN9J2ha4g/QB7D3g1Ij4vJnHOJAkXQnsS3p9zgZeoJD8kkYCc0lfhjQcmAUsopD8AJJGAK8C\n",
       "VwBPUkh2SZOAeaTskJ73q4A7KSA/gKSTgRnAKuAS4BXKef7PBE6tWLU78B0aeP5b+gy9cr534Czg\n",
       "uiYf0oDLb+hXs+Zb6yC9sV0fEfsDb9DLl920C0kHALvk5/xQ0kT5l1NIfuBI4PmImAScAFxDWfkB\n",
       "LibN9QwFvfazpyLigPwznfSBroj8krYgdeKdpP8HUyjotR8Rt/Q898ClwG00+Ppv6Q6dqvnegbH5\n",
       "u9bb2UrSi/n9inUTgYfy8sPAQRv6oDaghaSODOATYBQF5Y+IeyPi1/nX7YB3gEkUkj9/UdNOwKN5\n",
       "VTHPfVY9I2ZJ+Q8C5kfEZxGxNCKmUdBrv8olpA9zk2ggf6tfcm9wvvfBLyK6gC5JlatHRcQXebnn\n",
       "b9CWcv6eCYbOIr2xTy4lfw9Jz5BmTzyK9CZXSv6rgHOBqfn3Yl77pCtyO0t6ENicdHZWUv7tgZE5\n",
       "/1jS2XlJ+QGQtAfwdkS8L6mh/K1+hl5tnfO9F6KIOe0lTSG9qZ9XtamI/PmWwxTgrqpNbZtf0mnA\n",
       "woh4O6+qztq22bPXgcsiYgpwOvAHYGjF9nbPP4T0QeYY4Azg1qrt7Z6/x49J42iq1czf6h2653tP\n",
       "lksalpe3If1d2pakycBFwGER8SkF5Ze0Wx4ESUS8TLqKtkzS8NyknfMfDhwv6VnSm9rFlJOdiHg3\n",
       "Iubl5TeBpaTbjEW89kl5n42I1Tn/Mgp6/itMBJ7Jyw2997V6h17yfO8drPlENp/8dwCOBR5ryhFt\n",
       "AJLGkC67HhERH+fVxeQH9gN+BiBpS9IYgvmk3NDG+SPixIjYMyL2BuaQ7iEuoIDsAJJOknRpXh4P\n",
       "jCOdpZby2n8COFBSRx4gV8xrv4ekrYHlEbEqr2rova/lp34tbb53SXsBN5PKllYB/yaN9p5LKmNa\n",
       "AkzN95rbjqSfkEZ4/iOv6iZdfptDGfmHky61bguMAC4jjSO5nQLy98gd21ukN/kisucBv3eTLjsP\n",
       "Jd1DfolC8sOX///Pyr/OIpWslpR/V2BWRByRf9+KBvK3fIduZmZmtbX6JXczMzOrgzt0MzOzNuAO\n",
       "3czMrA24QzczM2sD7tDNzMzagDt0MzOzNuAO3czMrA38H5so7kAxBJmjAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3486920610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAfQAAABUCAYAAAB0vcXQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAADHVJREFUeJzt3X/s1VUdx/HnV2kqKIgOJCzp98tq1YZgIQXIMExFVppa\n",
       "DRMxaWlRrVprTTFqrqgsXfZDVExxU8eammmE0mipGc7EVr6ztMFSxFrAFxoocPvjnG9cb/C99369\n",
       "cO/3ntdj+26fe+5nd58X93LP/Xw+531OT6VSwczMzAa3g9p9AGZmZvbKuUM3MzPrAu7QzczMuoA7\n",
       "dDMzsy7gDt3MzKwLuEM3MzPrAkP6e1LShcCcqqYJwFuBW0g/Bp4D5kTEi5I+BiwAdgM/iYgbJL0K\n",
       "WAocB+wC5kbEM5LeBVwLVIC1EfGp1sYyMzMrS0+jdeiSpgDnAEOBeyJiuaRvAOuBm4FHgYnAS8Dv\n",
       "gSnAmcCEiPi0pFOAeRFxnqRVwBci4lFJy4CbI+K+VoczMzMrRTOX3C8DFgHTgLty293ADOBE4PcR\n",
       "0RsR24HfApOB6cDP8r73A5PzWfvrIuLRmtcwMzOzAWqoQ5c0EVgXEc8DwyLipfzUC8CrgTF5u8/G\n",
       "qvZ/AkTEbtIl9jHAv/eyr5mZmQ1Qv/fQq1xEuhdeq2cf+zfT3tCPikqlUunp2dfLmpmZdZ2mOr1G\n",
       "O/SpwCV5e6ukQyJiB3As8Gz+G1O1/7HAw1Xta/Ol9h7SQLqja/Z9tt4B9PT08MILvQ0ebncZNeqI\n",
       "YrOD8zt/uflLzg7OP2rUEU3tX/fsWNJYYGtE7MxNK4Gz8/ZZwL3A74CJkkZIOpx0/3w1sAL4cN53\n",
       "FvBAfp0nJU3O7R/Mr2FmZmYD1Mjl7rnAmyWtkXQa8GPgGkmbSKPYb80D4e4B/kE6A18VEb3AcmC6\n",
       "pM3AElKpGsAPgV/k9nER8UBLU5mZmRWm3w5d0tHA+cBY4AxgNnAp8ImIOBJYBlwgaRhwKmlw2yjS\n",
       "aPaRwEeAX0TECOBc4LP5pRcA03P7nySd2vJkZmZmBal3hj4DWBkR2yJiQ0TMx2VrZmZmHafeoLhx\n",
       "wFBJdwIjgSt4BWVrkgZctjZ+/Hh27txdN1AnWbz4KsaPn9DuwzAzswLU69APAo4iDVx7HfDrmucP\n",
       "WNnaY4891shuHWXIkN1Nj1Lcl1a9zmDl/M5fqpKzg/M3o16HvgF4KE8K87SkXuBFSYfmS+sHrGwt\n",
       "DZJfWH+3jjAfWMOmTf9pScmFSzec3/nLzF9ydnD+Zn/M1OvQVwBLJX2TdKY+DLiPVK62jJeXrS2R\n",
       "NIK0CMtk0sC34aSytRVUla1JelLS5Ij4Lens/+r6h3o0ML6pcO0zvN0HYGZmhal3ufstwCRgM/AM\n",
       "8DguWzMzM+s4jdy/vjcihue/2cBncNmamZlZR2mkQ68dyDYVl62ZmZl1lHr30CvA23LZ2lHA12hT\n",
       "2ZqZmZntW70O/SlgYUTcIekNpLK1g6ueP2Bla4PRkUcOddlaizi/85eq5Ozg/M3ot0OPiGeBO/L2\n",
       "05I2ACe0Y7W1wchla63h/M5fav6Ss4Pzt3S1NUkflXR53h5NGvB2I15tzczMrKPUu9x9F+mM/EFg\n",
       "HakM7VpctmZmZtZR+u3QI2JrRJwJrCLVoD8BfBqXrZmZmXWUugPSJB0PHE86AweXrZmZmXWcRkaY\n",
       "LwY+x54R6gMuWyOVwblszczMrMX6HeUu6XxgdUSskwT/X3bmsrV+uGytdZzf+UtVcnZw/mbUq0M/\n",
       "DXiDpA8BrwF2AL3tWW1t8HHZWms4v/OXmr/k7OD8LS1bi4jzIuLEiJhEGqW+iHQv/Ky8i8vWzMzM\n",
       "OkC9S+5DgaXAaOCNwO2k1dZWSvoBsAn4UkRsl9RXtlYBlkVEr6TlwNdzedou0hk/7ClbA3jaZWtm\n",
       "ZmavTL3712cAj0TENNJZ9yzgUly2ZmZm1lHqTf16e9XD44D1wDRgfm67G/gCEOSyNQBJ1WVrN+V9\n",
       "7wdu6Kds7b5XGsbMzKxUDY0wzzPF3UI6w3bZmpmZWYepN8odgIg4SdK7SJfYq7lsrR8uW2sd53f+\n",
       "UpWcHZy/GfUGxZ0AbIyI9RHxuKQhuGytYS5baw3nd/5S85ecHZy/pWVrwPuAzwNIOgYYBqzEZWtm\n",
       "ZmYdpV6H/iNgtKT1wF+B7aTO++K82tq5pNHtu4EvA2tIZ+AHkTry24AhkjYC1wNvkvR60r34qyVt\n",
       "ASawZzlWMzMzG4B6E8tsJ00oszYijgAmAVcAfwPmRcQxwFPAhaRR6ruAscA7SPO/jwB+DdwWESOB\n",
       "y4ErI+LPwBbg5Ih4DTDCpWtmZmYD18iAtNXAOXl7M+myu1dcMzMz6yB1O/SI2BUR2/LDeaRlVA93\n",
       "6ZqZmVnnaKhsDUDSbGAuMJN0mb2PS9f2wWVrreP8zl+qkrOD8zejoQ5d0kzgK8DMiNgiaaukQyJi\n",
       "By5d2yeXrbWG8zt/qflLzg7O3+qyNSSNABYDp0fEpty8kj0j0126ZmZm1maNXOo+FzgGWC/pL5Ie\n",
       "AG4Arsmla2cCt+aBcH0rrj0HrMpzuy8HpucV15YA1+bX7VtxbTMwziuumZmZDVwjHfotwFrgRuB7\n",
       "ETEd+CRecc3MzKxjNNKh7yAto/p8VZvL1szMzDpIo2VrO2qaveKamZlZB2m4bK0fLlvbB5ettY7z\n",
       "O3+pSs4Ozt+MgXboLltrgMvWWsP5nb/U/CVnB+dvedlalR72nF27bM3MzKyD1D1Dl/Qe4DpgNLBT\n",
       "0nzSaPalefvvwE0RsUvSl4Ffku6TL4yIXkm3AadI+g1ptbYL8kt/FviVpOFAL2mxFjMzMxuAuh16\n",
       "RDxMWj2t1vv3su9yUt15ddtu0mpstUYDj0XELEnHk2rbT2rkoM3MzOzlWjEobqD+V84WEU9KGinp\n",
       "8IjYuvfd/wk8uvenOk6aI+fss89s83E0b+NGXygxMxuM2tmhj+HlPXRf+dtTe9/95/nP9qfRo4e3\n",
       "+xDMzAyoVCpN7d/ODr1WD+ne+15VKpV9lcGZmZkVr53137VlbmNJ5WxmZmbWpHZ26CvIpW+SxgP/\n",
       "iIhtbTweMzOzQaun2Wv0rSTpSmAKsAu4JCKeaNvBmJmZDWJt7dDNzMysNbpyDnUzM7PSuEM3MzPr\n",
       "Au7QzczMukAn1aHvlaSrgHeTatQXRMSaNh/SfifpnaRZ9L4bET+Q9FrgZtIPsOeAORHxYjuPcX+S\n",
       "9C3gvaTP55XAGgrJL2kosJQ0NfKhwCJgLYXkB5B0GPBH4GukaReLyC5pGnAHKTuk930xcAsF5AeQ\n",
       "9DHgi8BO4DLgCcp5/y8E5lQ1TQDeShPvf0efoUuaCrwpIk4C5gFXt/mQ9rv8hf4d9ixyA+mL7ZqI\n",
       "mAL8lb3Pjd8VJJ0MvD2/56cC3weuoJD8wBnAIxExDTgHuIqy8gN8lTTXMxT02c9WRcTJ+W8B6Qdd\n",
       "EfklHU3qxCeT/h/MpqDPfkTc0PfeA5cDN9Hk57+jO3Rq5nsHRualWbvZDtKH+fmqtqnAXXn7bmDG\n",
       "gT6oA2g1qSMD2AwMo6D8EXF7RHw7PzwOWA9Mo5D8eaGm44F7clMx731WOyNmSflnACsjYltEbIiI\n",
       "+RT02a9xGenH3DSayN/pl9ybnO998IuIXcAuSdXNwyLipbzd92/QlXL+vgmG5pG+2GeWkr+PpAdJ\n",
       "syfOIn3JlZJ/MXAJMDc/LuazT7oi9zZJdwJHkc7OSso/Dhia848knZ2XlB8ASROBdRHxvKSm8nf6\n",
       "GXqtfud7L0QRc9pLmk36Ur+05qki8udbDrOBZTVPdW1+SecDqyNiXW6qzdq12bOngIURMRv4OHA9\n",
       "cHDV892e/yDSD5kPAhcAN9Y83+35+1xEGkdTq27+Tu/QPd97slXSIXn7WNK/S9eSNBP4CvCBiNhC\n",
       "QfklnZAHQRIRj5OuovVKOjTv0s35TwM+LOkh0pfaVyknOxHxbETckbefBjaQbjMW8dkn5X0oInbn\n",
       "/L0U9P5XmQo8mLeb+u7r9A695Pnee9jzi2wl+d8BOAu4ty1HdABIGkG67Hp6RGzKzcXkB94HfB5A\n",
       "0jGkMQQrSbmhi/NHxHkRcWJETAKWkO4h3k8B2QEkfVTS5Xl7NDCKdJZaymd/BTBdUk8eIFfMZ7+P\n",
       "pLHA1ojYmZua+u7r+KlfS5vvXdJ7gOtIZUs7gX+RRnsvJZUx/R2Ym+81dx1JF5NGeP4lN1VIl9+W\n",
       "UEb+Q0mXWl8LHAYsJI0j+SkF5O+TO7ZnSF/yRWTPA35vJV12Pph0D/kPFJIf/vf/f15+uIhUslpS\n",
       "/vHAoog4PT8eQxP5O75DNzMzs/o6/ZK7mZmZNcAdupmZWRdwh25mZtYF3KGbmZl1AXfoZmZmXcAd\n",
       "upmZWRdwh25mZtYF/guBBDTseT+U9wAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3486859d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "\n",
    "for feature in range(4):\n",
    "    data = [d['features'][feature] for d in dataset]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(4, 1, feature+1)\n",
    "    line = ax.hist(data, color='blue', lw=2)\n",
    "plt.show()\n",
    "##plt.hist(small);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks *very* much as if most features would be 0 most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with classifiers\n",
    "In order to test how well our ideas perform, we need a labeled training and test set (and eventually a validation set and a development set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 55686 entries, test set has 6192 entries.\n"
     ]
    }
   ],
   "source": [
    "current_best_score = 0.53344\n",
    "current_best_score_by_class = [ 0.00822475,  0.04901561,  0.03098987,  0.01030099,  0.01261864,  0.04582523,\n",
    "  0.0105592,   0.03471553,  0.01979984]\n",
    "training_set = []\n",
    "test_set = []\n",
    "complete_set = []\n",
    "\n",
    "# Build data structure for splitting\n",
    "data_by_class = {}\n",
    "for data in dataset:\n",
    "    if data['target'] in data_by_class:\n",
    "        data_by_class[data['target']].append(data)\n",
    "    else:\n",
    "        data_by_class[data['target']] = [data]\n",
    "\n",
    "# split\n",
    "for class_name, class_data in data_by_class.items():\n",
    "    for i, d in enumerate(class_data):\n",
    "        complete_set.append(d)\n",
    "        if i % 10 == 0: # 10% test set, 90% training set\n",
    "            test_set.append(d)\n",
    "        else:\n",
    "            training_set.append(d)\n",
    "            \n",
    "print(\"Training set has %i entries, test set has %i entries.\" % (len(training_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "y_train = numpy.array([d['target'] for d in training_set], dtype=numpy.int32)\n",
    "X_train = numpy.array([d['features'] for d in training_set], dtype=numpy.float32)\n",
    "y_test = numpy.array([d['target'] for d in test_set], dtype=numpy.int32)\n",
    "X_test = numpy.array([d['features'] for d in test_set], dtype=numpy.float32)\n",
    "y_complete = numpy.array([d['target'] for d in complete_set], dtype=numpy.int32)\n",
    "X_complete = numpy.array([d['features'] for d in complete_set], dtype=numpy.float32)\n",
    "\n",
    "X_competition_test = numpy.array([d['features'] for d in dataset_competition_test], dtype=numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import log_loss\n",
    "from math import log\n",
    "\n",
    "def log_loss_by_class(y_true, y_pred):\n",
    "    c = [0.0 for i in range(9)]\n",
    "    for tr, pred in zip(y_true, y_pred):\n",
    "        val = max(min(pred[tr], 1-10**(-15)),10**(-15))\n",
    "        c[tr] += -log(val)\n",
    "    return c\n",
    "\n",
    "def try_classifier(clf):\n",
    "    \"\"\"Train a classifier and score against our labeled test set\"\"\"\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    t2 = time.time()\n",
    "    print(\"%0.2f s for training, %0.2f s for scoring, got a score of %0.4f.\" % (t1-t0, t2-t1, score))\n",
    "    classesloss = log_loss_by_class(y_test, y_pred)\n",
    "    classesloss = numpy.array(classesloss)/len(y_pred)\n",
    "    improved = False\n",
    "    for i in range(9):\n",
    "        if classesloss[i] < current_best_score_by_class[i]:\n",
    "            improved = True\n",
    "    if improved:\n",
    "        print(\"!\"*80)\n",
    "        print(\"Improved! (partially)\")\n",
    "        print(classesloss)\n",
    "\n",
    "def create_submission(clf):\n",
    "    import gzip\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    score = log_loss(y_test, y_pred)\n",
    "    print(\"Expected score: %0.4f. Currently, the best submission at Kaggle is %0.4f.\" % (score, current_best_score))\n",
    "    y_pred = clf.predict_proba(X_competition_test)\n",
    "    with gzip.open(\"submission.csv.gz\", \"wb\") as f:\n",
    "        f.write(\"id,Class_1,Class_2,Class_3,Class_4,Class_5,Class_6,Class_7,Class_8,Class_9\\n\")\n",
    "        for i, pred in enumerate(y_pred, start=1):\n",
    "            f.write(str(i) + \",\" + \",\".join([str(el) for el in pred]) + \"\\n\")\n",
    "    print(\"http://www.kaggle.com/c/otto-group-product-classification-challenge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC\n",
    "Try it from http://scikit-learn.org/stable/auto_examples/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(gamma=2, C=1, probability=True)\n",
    "#try_classifier(svc_clf)  # This takes some hours on a strong machine and has a score of 1.8861\n",
    "#create_submission(svc_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#svc_linear_clf = SVC(kernel=\"linear\", C=0.025, probability=True)\n",
    "#try_classifier(svc_linear_clf)\n",
    "#create_submission(svc_linear_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#svc_sigmoid_clf = SVC(kernel=\"sigmoid\", C=0.025, probability=True)\n",
    "#try_classifier(svc_sigmoid_clf)\n",
    "#create_submission(svc_sigmoid_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.10 s for training, 0.00 s for scoring, got a score of 1.7765.\n",
      "2\n",
      "0.18 s for training, 0.00 s for scoring, got a score of 1.6224.\n",
      "3\n",
      "0.27 s for training, 0.00 s for scoring, got a score of 1.5006.\n",
      "4\n",
      "0.34 s for training, 0.00 s for scoring, got a score of 1.4203.\n",
      "5\n",
      "0.42 s for training, 0.00 s for scoring, got a score of 1.3342.\n",
      "6\n",
      "0.49 s for training, 0.00 s for scoring, got a score of 1.2577.\n",
      "7\n",
      "0.56 s for training, 0.00 s for scoring, got a score of 1.2316.\n",
      "8\n",
      "0.62 s for training, 0.00 s for scoring, got a score of 1.1757.\n",
      "9\n",
      "0.64 s for training, 0.00 s for scoring, got a score of 1.1673.\n",
      "10\n",
      "0.62 s for training, 0.00 s for scoring, got a score of 1.1957.\n",
      "11\n",
      "0.67 s for training, 0.00 s for scoring, got a score of 1.2192.\n",
      "12\n",
      "0.72 s for training, 0.00 s for scoring, got a score of 1.2639.\n",
      "13\n",
      "0.77 s for training, 0.00 s for scoring, got a score of 1.3864.\n",
      "14\n",
      "0.82 s for training, 0.00 s for scoring, got a score of 1.5591.\n",
      "15\n",
      "0.87 s for training, 0.00 s for scoring, got a score of 1.7492.\n",
      "16\n",
      "0.91 s for training, 0.00 s for scoring, got a score of 1.9822.\n",
      "17\n",
      "0.96 s for training, 0.00 s for scoring, got a score of 2.2358.\n",
      "18\n",
      "1.00 s for training, 0.00 s for scoring, got a score of 2.5671.\n",
      "19\n",
      "1.05 s for training, 0.00 s for scoring, got a score of 2.8870.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for i in range(6, 11):\n",
    "    print(i)\n",
    "    decision_tree_clf = DecisionTreeClassifier(max_depth=i)\n",
    "    try_classifier(decision_tree_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58 s for training, 0.00 s for scoring, got a score of 1.1618.\n",
      "Expected score: 1.1618. Currently, the best submission at Kaggle is 0.5380.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "decision_tree_clf = DecisionTreeClassifier(max_depth=9)\n",
    "try_classifier(decision_tree_clf)\n",
    "create_submission(decision_tree_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.54 s for training, 0.09 s for scoring, got a score of 2.0485.\n",
      "Expected score: 2.0485. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#adaboost_clf = AdaBoostClassifier()\n",
    "#try_classifier(adaboost_clf)\n",
    "#create_submission(adaboost_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.72 s for training, 34.78 s for scoring, got a score of 2.3611.\n",
      "Expected score: 2.3611. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#knnclf = KNeighborsClassifier(5)\n",
    "#try_classifier(knnclf) \n",
    "#create_submission(knnclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26 s for training, 0.02 s for scoring, got a score of 1.0216.\n",
      "Expected score: 1.0216. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "lda_clf = LDA()\n",
    "try_classifier(lda_clf)\n",
    "create_submission(lda_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24 s for training, 0.09 s for scoring, got a score of 5.9614.\n",
      "Expected score: 5.9614. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "from sklearn.qda import QDA\n",
    "qda_clf = QDA()\n",
    "try_classifier(qda_clf)\n",
    "create_submission(qda_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 s for training, 0.03 s for scoring, got a score of 7.1846.\n",
      "Expected score: 7.1846. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussiannb_clf = GaussianNB()\n",
    "try_classifier(gaussiannb_clf)\n",
    "create_submission(gaussiannb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 93)\n",
      "12.59 s for training, 0.01 s for scoring, got a score of 30.5374.\n",
      "Expected score: 30.5374. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\"\n",
    "from sklearn.mixture import GMM\n",
    "gmm_diag_clf = GMM(n_components=9, covariance_type='diag', init_params='wc', n_iter=20)\n",
    "t0 = time.time()\n",
    "X_train_by_class = {}\n",
    "for i in range(9):\n",
    "    X_train_by_class[i] = []\n",
    "for x, y in zip(X_train, y_train):\n",
    "    X_train_by_class[y].append(x)\n",
    "init = numpy.array([numpy.array(X_train_by_class[i]).mean(axis=0) for i in range(9)])\n",
    "print(init.shape)\n",
    "gmm_diag_clf.means = init\n",
    "gmm_diag_clf.fit(X_train)\n",
    "t1 = time.time()\n",
    "y_pred = gmm_diag_clf.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_pred)\n",
    "t2 = time.time()\n",
    "print(\"%0.2f s for training, %0.2f s for scoring, got a score of %0.4f.\" % (t1-t0, t2-t1, score))\n",
    "create_submission(gmm_diag_clf)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Geometric distribution\n",
    "As every feature represents a count, every feature is very likely to follow a geometric distribution:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(X=n)=p(1-p)^n\n",
    "\\end{equation*}\n",
    "\n",
    "The simplest way to use this fact is to make a maximum likelihood estimiation seperately for each feature and class on the training data (as training).\n",
    "\n",
    "After that, the evaluation of new recordings with the Naive bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 s for training, 0.01 s for scoring, got a score of 3.4472.\n",
      "Expected score: 3.4472. Currently, the best submission at Kaggle is 0.5380.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#nb_clf = MultinomialNB(alpha=0.2, fit_prior=True, class_prior=None)\n",
    "#try_classifier(nb_clf)\n",
    "#create_submission(nb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.03 s for training, 0.07 s for scoring, got a score of 0.5938.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Improved! (partially)\n",
      "[ 0.05308346  0.13177644  0.13650979  0.06674199  0.00510585  0.05149895\n",
      "  0.05173902  0.04835077  0.04894951]\n",
      "Expected score: 0.5938. Currently, the best submission at Kaggle is 0.5334.\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "#a = \"\"\"\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "nb_clf = GradientBoostingClassifier(loss='deviance',\n",
    "                                    learning_rate=0.1,\n",
    "                                    n_estimators=100,\n",
    "                                    subsample=1.0,\n",
    "                                    min_samples_split=2,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    max_depth=3,\n",
    "                                    init=None,\n",
    "                                    random_state=None,\n",
    "                                    max_features=None,\n",
    "                                    verbose=0,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    warm_start=False)\n",
    "try_classifier(nb_clf)\n",
    "create_submission(nb_clf)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00822475, 0.04901561, 0.03098987, 0.01030099, 0.01261864, 0.04582523, 0.0105592, 0.03471553, 0.01979984]\n"
     ]
    }
   ],
   "source": [
    "print(current_best_score_by_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Install [lasagne](http://lasagne.readthedocs.org/en/latest/user/installation.html#install-from-source) (from [source](https://github.com/benanne/Lasagne)) for the following parts:\n",
    "\n",
    "```bash\n",
    "$ git clone git@github.com:benanne/Lasagne.git\n",
    "$ cd Lasagne\n",
    "$ sudo -H python setup.py install\n",
    "```\n",
    "\n",
    "\n",
    "See [danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/) for an introduction to lasagne.\n",
    "\n",
    "The [Lasagne Tutorial](http://nbviewer.ipython.org/github/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb) is even better (and uses iPython :-) )\n",
    "\n",
    "Don't forget to set `~/.theanorc` to\n",
    "\n",
    "```text\n",
    "[global]\n",
    "exception_verbosity=high\n",
    "floatX=float32\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "N_CLASSES = 9\n",
    "\n",
    "# First, construct an input layer.\n",
    "# The shape parameter defines the expected input shape, which is just the shape of our data matrix X.\n",
    "l_in = lasagne.layers.InputLayer(shape=X_train.shape)\n",
    "# A dense layer implements a linear mix (xW + b) followed by a nonlinearity.\n",
    "hiddens = [32, 32, 18, 32]\n",
    "layers = [l_in]\n",
    "\n",
    "def relu(x):\n",
    "    return theano.tensor.switch(x<0, 0, x)\n",
    "\n",
    "for n_units in hiddens:\n",
    "    l_hidden_1 = lasagne.layers.DenseLayer(\n",
    "        layers[-1],  # The first argument is the input to this layer\n",
    "        num_units=n_units,  # This defines the layer's output dimensionality\n",
    "        nonlinearity=lasagne.nonlinearities.tanh)  # Various nonlinearities are available such as relu\n",
    "    layers.append(l_hidden_1)\n",
    "# For our output layer, we'll use a dense layer with a softmax nonlinearity.\n",
    "l_output = lasagne.layers.DenseLayer(layers[-1], num_units=N_CLASSES, \n",
    "                                     nonlinearity=lasagne.nonlinearities.softmax)\n",
    "# Now, we can generate the symbolic expression of the network's output given an input variable.\n",
    "net_input = T.matrix('net_input')\n",
    "net_output = l_output.get_output(net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should apply multi-cass log loss:\n",
    "    \n",
    "\\begin{equation*}\n",
    "log loss = -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^My_{ij}\\log(p_{ij}),\n",
    "\\end{equation*}\n",
    "\n",
    "where $N$ is the number of products in the test set, $M=9$ is the number of class labels, log is the natural logarithm, $y_{ij}$ is 1 if observation $i$ is in class $j$ and $0$ otherwise, and $p_{ij}$ is the predicted probability that observation $i$ belongs to class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As a loss function, we'll use Theano's categorical_crossentropy function.\n",
    "# This allows for the network output to be class probabilities,\n",
    "# but the target output to be class labels.\n",
    "true_output = T.ivector('true_output')\n",
    "loss = T.mean(T.nnet.categorical_crossentropy(net_output, true_output))\n",
    "\n",
    "reg = lasagne.regularization.l2(l_output)\n",
    "loss = loss + 0.001*reg\n",
    "#NLL_LOSS = -T.sum(T.log(p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "# Retrieving all parameters of the network is done using get_all_params,\n",
    "# which recursively collects the parameters of all layers connected to the provided layer.\n",
    "all_params = lasagne.layers.get_all_params(l_output)\n",
    "\n",
    "# Now, we'll generate updates using Lasagne's SGD function\n",
    "updates = lasagne.updates.momentum(loss, all_params, learning_rate=0.1)\n",
    "\n",
    "# Finally, we can compile Theano functions for training and computing the output.\n",
    "train = theano.function([net_input, true_output], loss, updates=updates)\n",
    "get_output = theano.function([net_input], net_output)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#X_train_s = scaler.fit_transform(X_train)\n",
    "#X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# Train\n",
    "epochs = 500\n",
    "for n in range(epochs):\n",
    "    train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected score: 0.5438. Currently, our best submission at Kaggle is 0.5334.\n",
      "[ 0.04642513  0.10722609  0.14724586  0.0660733   0.00659836  0.04373696\n",
      "  0.04468819  0.04253366  0.03929795]\n",
      "0.543825498947\n",
      "http://www.kaggle.com/c/otto-group-product-classification-challenge\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "y_pred = get_output(X_test)\n",
    "score = log_loss(y_test, y_pred)\n",
    "print(\"Expected score: %0.4f. Currently, our best submission at Kaggle is %0.4f.\" % (score, current_best_score))\n",
    "\n",
    "classesloss = log_loss_by_class(y_test, y_pred)\n",
    "print(numpy.array(classesloss)/len(y_pred))\n",
    "print(sum(classesloss)/len(y_pred))\n",
    "\n",
    "y_pred = get_output(X_competition_test)\n",
    "with gzip.open(\"submission.csv.gz\", \"wb\") as f:\n",
    "    f.write(\"id,Class_1,Class_2,Class_3,Class_4,Class_5,Class_6,Class_7,Class_8,Class_9\\n\")\n",
    "    for i, pred in enumerate(y_pred, start=1):\n",
    "        f.write(str(i) + \",\" + \",\".join([str(el) for el in pred]) + \"\\n\")\n",
    "print(\"http://www.kaggle.com/c/otto-group-product-classification-challenge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Other\n",
    "From https://gist.github.com/chrisdubois/6b93a8028f4dc40cab49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00822475  0.04901561  0.03098987  0.01030099  0.01261864  0.04582523\n",
      "  0.0105592   0.03471553  0.01979984]\n",
      "0.222049671137\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
